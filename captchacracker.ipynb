{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP85zNMwzV/zVhja/P8JzRX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyemsnail/captcha_project/blob/main/captchacracker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLYURBXx0ijI",
        "outputId": "43552b27-ba48-4fef-fa79-d8eecee8d254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting CaptchaCracker\n",
            "  Downloading CaptchaCracker-0.0.7-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading CaptchaCracker-0.0.7-py3-none-any.whl (7.3 kB)\n",
            "Installing collected packages: CaptchaCracker\n",
            "Successfully installed CaptchaCracker-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install CaptchaCracker"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==3.20.1\n",
        "!pip install tensorflow==2.9.1 keras==2.9.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s_CqAsxtw2Fa",
        "outputId": "3b5f7d50-449f-46b9-a486-4c7aa4fbb92e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting protobuf==3.20.1\n",
            "  Using cached protobuf-3.20.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (698 bytes)\n",
            "Using cached protobuf-3.20.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-ai-generativelanguage 0.6.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-api-core 2.19.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.63.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.25.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigtable 2.26.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-functions 1.16.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-iam 2.15.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-language 2.13.4 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-pubsub 2.23.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-translate 3.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "googleapis-common-protos 1.64.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "pandas-gbq 0.23.1 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.20.1 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "967dae223de94936afe8e91a91c5392e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.9.1 in /usr/local/lib/python3.10/dist-packages (2.9.1)\n",
            "Requirement already satisfied: keras==2.9.0 in /usr/local/lib/python3.10/dist-packages (2.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.12)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (3.11.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (24.1)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.9.1)\n",
            "  Using cached protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.1) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.2.2)\n",
            "Using cached protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.1\n",
            "    Uninstalling protobuf-3.20.1:\n",
            "      Successfully uninstalled protobuf-3.20.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-aiplatform 1.63.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigtable 2.26.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-functions 1.16.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.15.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.13.4 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.23.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "googleapis-common-protos 1.64.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "pandas-gbq 0.23.1 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.6 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.19.6 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.19.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "ad4b1c47f60140b7b3369818009ea7ed"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show CaptchaCracker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbTkqotFjKtj",
        "outputId": "8fa4c23f-7d39-4cc9-bd8d-5327d6d2e64e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: CaptchaCracker\n",
            "Version: 0.0.7\n",
            "Summary: CaptchaCracker is an open source Python library that provides functions to create and apply deep learning models for Captcha Image recognition.\n",
            "Home-page: https://github.com/WooilJeong/CaptchaCracker\n",
            "Author: Wooil Jeong\n",
            "Author-email: wooil@kakao.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy>=1.20 protobuf==3.19.6 tensorflow==2.9.1"
      ],
      "metadata": {
        "id": "RPNoK8KG_uTI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsAQqEagPua_",
        "outputId": "2ce62a1e-eab7-40e9-cee0-f9b05f77c27b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/sample (1)/train_numbers_only.zip'"
      ],
      "metadata": {
        "id": "tTy0V23gQJaW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 모델 학습\n",
        "import glob\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "# Google Drive 경로로 수정\n",
        "training_img_path_list = glob.glob('/content/drive/MyDrive/sample (1)/train_numbers_only/*.png')\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "\n",
        "CM = cc.CreateModel(training_img_path_list, img_width, img_height)\n",
        "\n",
        "model = CM.train_model(epochs=100)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UxtQv7T5CAg",
        "outputId": "99dda6fa-309f-4694-f077-d0f5f2e43e9f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 36s 720ms/step - loss: 19.5287 - val_loss: 15.6058\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 16s 471ms/step - loss: 15.5938 - val_loss: 15.5966\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 16s 468ms/step - loss: 15.5916 - val_loss: 15.5849\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 17s 499ms/step - loss: 15.5882 - val_loss: 15.5806\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 18s 510ms/step - loss: 15.5845 - val_loss: 15.5776\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 15s 441ms/step - loss: 15.5830 - val_loss: 15.5715\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 16s 455ms/step - loss: 15.5876 - val_loss: 15.5835\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 15s 440ms/step - loss: 15.5743 - val_loss: 15.5894\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 15s 449ms/step - loss: 15.5750 - val_loss: 15.5824\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 19s 552ms/step - loss: 15.5683 - val_loss: 15.5646\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 15s 453ms/step - loss: 15.5667 - val_loss: 15.5629\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 17s 513ms/step - loss: 15.5595 - val_loss: 15.5527\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 15s 450ms/step - loss: 15.5535 - val_loss: 15.5373\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 15s 445ms/step - loss: 15.5331 - val_loss: 15.5332\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 15s 450ms/step - loss: 15.5144 - val_loss: 15.5102\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 16s 466ms/step - loss: 15.4706 - val_loss: 15.4158\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 16s 453ms/step - loss: 15.2440 - val_loss: 15.0008\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 15s 449ms/step - loss: 14.6497 - val_loss: 13.8445\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 17s 486ms/step - loss: 13.2292 - val_loss: 11.9053\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 15s 450ms/step - loss: 10.8318 - val_loss: 7.6645\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 15s 451ms/step - loss: 6.7430 - val_loss: 3.4052\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 15s 454ms/step - loss: 3.1366 - val_loss: 1.4351\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 15s 453ms/step - loss: 1.7763 - val_loss: 0.9865\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 16s 456ms/step - loss: 1.1421 - val_loss: 0.8457\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 16s 450ms/step - loss: 0.8579 - val_loss: 0.7219\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 16s 476ms/step - loss: 0.7812 - val_loss: 0.6791\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 15s 449ms/step - loss: 0.6916 - val_loss: 0.6040\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 15s 450ms/step - loss: 0.5410 - val_loss: 0.6006\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 16s 457ms/step - loss: 0.6075 - val_loss: 0.6241\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 15s 451ms/step - loss: 0.5731 - val_loss: 0.5852\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 16s 459ms/step - loss: 0.4714 - val_loss: 0.4952\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 15s 455ms/step - loss: 0.4386 - val_loss: 0.5270\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 16s 455ms/step - loss: 0.4087 - val_loss: 0.4397\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 19s 543ms/step - loss: 0.4267 - val_loss: 0.4492\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 16s 456ms/step - loss: 0.3079 - val_loss: 0.4872\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 16s 472ms/step - loss: 0.3170 - val_loss: 0.4813\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 16s 460ms/step - loss: 0.3285 - val_loss: 0.4631\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 16s 454ms/step - loss: 0.2683 - val_loss: 0.4533\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 16s 456ms/step - loss: 0.3047 - val_loss: 0.4281\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 15s 452ms/step - loss: 0.2508 - val_loss: 0.4570\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 15s 454ms/step - loss: 0.3132 - val_loss: 0.4229\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 22s 644ms/step - loss: 0.2531 - val_loss: 0.4163\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 15s 455ms/step - loss: 0.2295 - val_loss: 0.4366\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 16s 446ms/step - loss: 0.2424 - val_loss: 0.4328\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 16s 458ms/step - loss: 0.2053 - val_loss: 0.4372\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 15s 449ms/step - loss: 0.1727 - val_loss: 0.4210\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 15s 453ms/step - loss: 0.1751 - val_loss: 0.4800\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 18s 526ms/step - loss: 0.1871 - val_loss: 0.4062\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 15s 455ms/step - loss: 0.1340 - val_loss: 0.4288\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 16s 459ms/step - loss: 0.1097 - val_loss: 0.4317\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 16s 460ms/step - loss: 0.1273 - val_loss: 0.4888\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 16s 457ms/step - loss: 0.1773 - val_loss: 0.4487\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 15s 454ms/step - loss: 0.1551 - val_loss: 0.4245\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 16s 457ms/step - loss: 0.1224 - val_loss: 0.3918\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 16s 457ms/step - loss: 0.1249 - val_loss: 0.5199\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 18s 524ms/step - loss: 0.1209 - val_loss: 0.4256\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 16s 455ms/step - loss: 0.1353 - val_loss: 0.4515\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 15s 442ms/step - loss: 0.1036 - val_loss: 0.4423\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 16s 457ms/step - loss: 0.0862 - val_loss: 0.4420\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 16s 454ms/step - loss: 0.1300 - val_loss: 0.4618\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 16s 457ms/step - loss: 0.1385 - val_loss: 0.5076\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 15s 455ms/step - loss: 0.1293 - val_loss: 0.5005\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 18s 533ms/step - loss: 0.1091 - val_loss: 0.4685\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 15s 454ms/step - loss: 0.1031 - val_loss: 0.4787\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 15s 450ms/step - loss: 0.0891 - val_loss: 0.4914\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 15s 451ms/step - loss: 0.0789 - val_loss: 0.4993\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 16s 469ms/step - loss: 0.1005 - val_loss: 0.5286\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 15s 453ms/step - loss: 0.1451 - val_loss: 0.4299\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 15s 453ms/step - loss: 0.1026 - val_loss: 0.4833\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 15s 452ms/step - loss: 0.0840 - val_loss: 0.5156\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 15s 453ms/step - loss: 0.0889 - val_loss: 0.4977\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 16s 454ms/step - loss: 0.0968 - val_loss: 0.4873\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 16s 465ms/step - loss: 0.0887 - val_loss: 0.4987\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 16s 454ms/step - loss: 0.0767 - val_loss: 0.5275\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 15s 447ms/step - loss: 0.1552 - val_loss: 0.5251\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 15s 453ms/step - loss: 0.1350 - val_loss: 0.4368\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 15s 447ms/step - loss: 0.0977 - val_loss: 0.5207\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 15s 451ms/step - loss: 0.0850 - val_loss: 0.4718\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 18s 543ms/step - loss: 0.0965 - val_loss: 0.5416\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 15s 455ms/step - loss: 0.0537 - val_loss: 0.4671\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 16s 455ms/step - loss: 0.0558 - val_loss: 0.5001\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 16s 450ms/step - loss: 0.0699 - val_loss: 0.5184\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 15s 453ms/step - loss: 0.0609 - val_loss: 0.4206\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 15s 453ms/step - loss: 0.0836 - val_loss: 0.4958\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 16s 456ms/step - loss: 0.0677 - val_loss: 0.5664\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 15s 452ms/step - loss: 0.0500 - val_loss: 0.5214\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 18s 524ms/step - loss: 0.0451 - val_loss: 0.4805\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 16s 456ms/step - loss: 0.0456 - val_loss: 0.5691\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 16s 456ms/step - loss: 0.0522 - val_loss: 0.4418\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 16s 455ms/step - loss: 0.0498 - val_loss: 0.5374\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 16s 460ms/step - loss: 0.0615 - val_loss: 0.4796\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 15s 444ms/step - loss: 0.0692 - val_loss: 0.4605\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 15s 452ms/step - loss: 0.0509 - val_loss: 0.4744\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 18s 527ms/step - loss: 0.0297 - val_loss: 0.4601\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 15s 449ms/step - loss: 0.0525 - val_loss: 0.4551\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 15s 452ms/step - loss: 0.0918 - val_loss: 0.4768\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 15s 451ms/step - loss: 0.0675 - val_loss: 0.5016\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 15s 451ms/step - loss: 0.0415 - val_loss: 0.4879\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 15s 452ms/step - loss: 0.0317 - val_loss: 0.5172\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 16s 456ms/step - loss: 0.0401 - val_loss: 0.5420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 학습 결과를 가중치 저장\n",
        "model.save_weights(\"/content/drive/MyDrive/weights.h5\")"
      ],
      "metadata": {
        "id": "wwI_iAQ1Jkpv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(1)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 296337\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test.png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q17xiIycMjC",
        "outputId": "8aacfab8-c942-4fb7-9fe0-70a9f293c5f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "296337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(2)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 084720\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(2).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLW76cBSpGsk",
        "outputId": "200381fc-5ddf-4115-e55f-7f93cf201c1f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "05770[UNK]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(3)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 580274\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(3).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq3XXFAm59DD",
        "outputId": "a8f13df2-1a99-4156-b84c-9529442ca486"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "530274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(4)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 177243\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(4).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa2A8dAy6c4P",
        "outputId": "adcb0d44-12d5-4b5a-a6ac-31b3c3650b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "177243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(5)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 645038\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(5).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZtsO8RG621o",
        "outputId": "70f36262-cf46-409d-dc5a-667e064ce16a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "645033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(6)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 578451\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(6).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwrt5tz58LWf",
        "outputId": "3b30cb5a-d033-4589-ab2f-3e2c31b19561"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "573451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(7)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 970836\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(7).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PdCIVSC8yCB",
        "outputId": "f85032ab-effb-4ad8-e731-dd67a60cd914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "970836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(8)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 771029\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(8).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q5Idnm18-7k",
        "outputId": "3ea0dfaf-0a92-412e-de88-fd98ed94af34"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "771102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(9)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 096340\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(9).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaRW-Bbk9XMH",
        "outputId": "3e55c8f7-cbac-4bd2-d712-875569967663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "096340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(10)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 911757\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(10).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XudHg_n9xXb",
        "outputId": "4f63487f-56e6-48d2-e543-49a862305c70"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7df7a713dc60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "911755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(11)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 862274\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(11).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8uQsqnSSSuu",
        "outputId": "5b9302fe-996f-47ab-b3d8-efad1a2b341d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "952274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(12)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 920062\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(12).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNgKEkajSXy3",
        "outputId": "754c1b0b-2e88-468b-f2af-49b3ec647fa9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "920162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(13)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 457872\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(13).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugOQ_DEpSbOq",
        "outputId": "586e1ae8-e643-45d9-a5a5-9c0fe71bd536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "457872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(14)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 652837\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(14).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb7rPV8nSdM6",
        "outputId": "6ccbedff-912f-4815-8f8f-8c7945deff56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "652837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(15)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 584735\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(15).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1l-UsldSfEG",
        "outputId": "60f83529-31dc-44d3-e5c5-ffd67533e84d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7a232b8bd870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "534735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(16)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 423014\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(16).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_HDEfb3SgqW",
        "outputId": "880d918b-1f62-4bb0-8765-1f23f275f478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "423014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(17)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 721797\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(17).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDH2_lZgSiyT",
        "outputId": "4cc98e55-99f9-47e8-f75f-2b9749f9980c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "721797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(18)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 569777\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(18).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QedUtJfFSlUg",
        "outputId": "00a1e72f-9718-477f-ddd2-0a2077fcecf3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "369777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(19)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 559958\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(19).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeEzEIGPSnNM",
        "outputId": "2f769c95-755f-4b64-ebb0-93336740b777"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "559953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 저장된 모델 기반으로 예측하기(20)\n",
        "import CaptchaCracker as cc\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "max_length = 6\n",
        "\n",
        "characters = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "\n",
        "weights_path = \"/content/drive/MyDrive/weights.h5\"\n",
        "\n",
        "AM = cc.ApplyModel(weights_path, img_width, img_height, max_length, characters)\n",
        "\n",
        "### test 숫자 467299\n",
        "target_img_path = \"/content/drive/MyDrive/captcha_test(20).png\"\n",
        "\n",
        "pred = AM.predict(target_img_path)\n",
        "\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to0e3DjUSppc",
        "outputId": "9a16b2f5-5bdd-4062-8ca4-21e6edb83943"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "467255\n"
          ]
        }
      ]
    }
  ]
}